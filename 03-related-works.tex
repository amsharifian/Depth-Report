%!TEX root = main.tex

% Notes 

\section{Hardware from High-level languages}

We discuss different languages and their level of abstraction to translates their behavioral specification to structured specification.



\subsection{Intorduction to HLS}
\cite{gajski_1994_introduction}

\subsection{Chimps, CASH, AHRL}

Chimps~\cite{chimps}, CASH~\cite{budiu_pegasus_2002,budiu_cash_2002}, AHRL~\cite{ahrl}
% * Generate hardware from ANSI C
% * mapping each C language construct in a dataflow graph to an HDL block.
%

\subsection{Bluespec}
Bluespec~\cite{bluespec}
% * generates hardware from purely functional description
% * Rule based hardware design language
% * The rules are atomic operations predicated with a condition.
% * They give the impression of freezing the rest of the system when a given rule’s action is carried out after the rule’s predicate is true.
% * There is an implicit parallelism in this specification, because it is possible for multiple rules to be activated and executed in parallel.
% *The compiler automatically schedules the rules such that they are either conflict-free or combined sequentially to preserve the promised atomicity semantic.
%

\subsection{Vivado/Autopilot / Legup / Intel's FPGA SDK for OpenCL, and SDAccel}

Vivado/Autopilot~\cite{vivado,vivadohls,autopilot} /Legup~\cite{canis_2011_legup} / Intel's FPGA SDK for OpenCL~\cite{opencl_sdk}, and SDAccel~\cite{sdaccel}
% * Applications can be expressed at a high level, in terms of arrays and untimed, nested loops.
% * commercial HLS tool that generates hardware from C/C++/SystemC languages
% * Imperative design description
%

\subsection{ElasticFlow / CGPA}

ElasticFlow~\cite{elasticFlow} / CGPA~\cite{cgpa} / Dynamic schedule dataflow~\cite{josipovic_fpga_2018_dynamically}
% * More recent works like ElasticFlow and CGPA
% * generate coarse-grained pipelines using FIFOs in between stages for communication.
%

\subsection{Gorill}
Gorill~\cite{lavasani_thesis}
% * Gorilla++ generates custom hardware for applications with irregular dataflow 
% * support multi-threading and lock-based synchronization

\subsection{Kiwi}
Kiwi~\cite{kiwi}
% * translates a set of C# parallel constructs to hardware units (monitor, event, lock)
Kiwi translates a set of $C\#$ parallel constructs (e.g., event, monitor,
and lock) to corresponding hardware units.

\subsection{Lime}
Lime~\cite{lime}
% * hardware from functional parallel patterns. (map, reduce, split, join)
% * Java and automatically targets CPUs, GPUs, and FPGAs
%
Lime is a Java-based programming model and runtime from IBM which aims to provide a single unified language to program heterogeneous architectures. Lime natively supports custom bit precisions and includes collection operations, with parallelism in such operations inferred by the compiler. Coarse-grained pipeline and data parallelism are expressed through ``tasks''. Coarse-grained streaming computation graphs can be constructed using built-in constructs like \texttt{\small{connect}}, \texttt{\small{split}}, and \texttt{\small{join}}. The Lime runtime system handles buffering, partitioning, and scheduling of stream graphs. However, coarse-grained pipelines which deviate from the streaming model are not supported, and the programmer has to use a low-level messaging API to handle coarse-grained graphs with feedback loops. Additionally, the compiler does not perform automatic design tuning. Finally, the compiler's ability to instantiate banked and buffered memories is unclear as details on banking multi-dimensional data structures for arbitrary access patterns are not specified.

\subsection{CMOST/ParallelXL}
CMOST~\cite{zhang_DAC_2015_cmost}, ParallelXL~\cite{chen_micro_2018_parallelXL}
% * C-to-FPGA framework that uses task-level modeling



\section{Image Processing DSLs}

\subsection{HIPACC}
HIPACC~\cite{membarth_2016_hipa}
% * source - to - source C like compiler
% * generate CUDA, openCL, Renderscripts target GPU
% * make use of different memory hierarchy based on limit set of access pattern
% * support fix set of reduction function
% * unroll only if kernel size is known
% * heuristic pick best configuration (similar to our DSE)
%

\subsection{Rigel}
Rigel~\cite{hegarty_2016_rigel}
% * Generate verilog
% * Coarse-grain pipeline
% * very similar control semantics to plasticine. Use
% tokens/back pressure to allow each pipeline stage to fire at their perspective rate
% * Multi-rate line buffer template
%

\subsection{Darkroom}
Darkroom~\cite{darkroom}
% * target ASIC, FPGA, fast CPU
% * generate structured verilog
% * line buffer
% * scheduling for inner loop pipeline. Use ILP to improve pipeline delay
%

\subsection{PolyMage}
PolyMage~\cite{mullapudi_asplos_2015_polymage}
% * point=wise, stencil, sampling, operation
% * functional (in a kind of awkward way)
% * python
% * generate openMP/C++
% * generate high-level synthesis tool
% * line buffer


\subsection{Generators}

\subsection{Genesis2/ OpenPiton}
Genesis2~\cite{genesis2}
% * Adds Perl scripting support to SystemVerilog
% * Improve procedural generation
%
OpenPiton~\cite{balkind_asplos_2016_openpiton}
% * written in industry standard Verilog
% * FPGA synthesis scripts as well as ASIC backend scripts.

Genesis2 uses Perl to provide more flexible parameterization and elaboration of hardware blocks written in SystemVerilog.

OpenPiton has been designed as a platform to enable atscale manycore research. An explicit design goal of OpenPiton is that it should be easy to use by other researchers. To
support this, OpenPiton provides a high degree of integration and configurability. Unlike many other designs where
the pieces are provided, but it is up to the user to compose
them together, OpenPiton is designed with all of the components integrated into the same easy to use build infrastructure providing push-button scalability. Computer architecture researchers can easily deploy OpenPiton’s source code,
add in modifications and explore their novel research ideas
in the setting of a fully working system. Over 8000 targeted,
high-coverage test cases are provided to enable researchers
to innovate with a safety net that ensures functionality is
maintained. OpenPiton’s open source nature also makes it
easy to release modifications and reproduce previous work
for comparison or reuse.
Beyond being a platform designed by computer architects for use by computer architects, OpenPiton enables researchers in other fields including OS, security, compilers,
runtime tools, systems, and even CAD tool design to conduct research at-scale. In order to enable such a wide range
of applications, OpenPiton is configurable and extensible.
The number of cores, attached I/O, size of caches, number
of TLB entries, presence of an FPU, number of threads, and
network topology are all configurable from a single configuration file. OpenPiton is easy to extend; the presence of a
well documented core, a well documented coherence protocol, and an easy to interface NoC make adding research
features easy. Research extensions to OpenPiton that have
already been built include several novel memory system explorations, an Oblivious RAM controller, and a new in-core
thread scheduler. The validated and mature ISA and software
ecosystem support OS and compiler research. The release of
OpenPiton’s ASIC synthesis, FPGA synthesis, and back-end
(Place and Route) scripts make it easy for others to port to
new process technologies or FPGAs. In particular, this enables CAD researchers who need large netlists to evaluate
their algorithms at-scale.


\paragraph{Conclusion: } While these improvements allow for more powerful meta-programming compared to Verilog \texttt{\small{generate}} statements, users still write programs at a timed circuit level.

% \subsection{Hardware generator languages}
% \begin{enumerate}
%     \item Chisel, Firrtl
%     \item Rocket core
% \end{enumerate}
