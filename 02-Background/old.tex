%!TEX root = main.tex

% NOTES:
%   * There is a shift to accelerator design
%   * CPUs are inefficient
%   * Fixed accelerators are hard to program
%   * Alternative is FPGA/CGRA
%   * There are challenges with programming FPGA/CGRA
%   * HLS is one solution

%


\section{Abstraction Levels}

The growing capabilities of silicon technology over the previous decades has forced design methodologies and tools to move to higher levels of abstraction
In order to explain the relationship between different design methodologies on
different abstraction levels, we will use the Y-Chart~\cite{walker_1985_y_model} to explain differences between different design tools and different design methodologies in which these tools were used.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Introduction/Y-Chart.pdf}
    \caption{Y-Chart}
    \label{fig:y-chart}
\end{figure}

Y-Chart divides design representation into three domains:1)Behavioral, it can also called functionality and specification, 2)Structural, also called netlist or a block diagram and 3)Physical, usually called layout or board design. Behavior represents a design as a black-box but it describes the output base on inputs over time. What behavior representation doesn't specify is how the black-box is structured or how to build the black-box. This is the task of structural representation. In this specification, black-box is represented as a set of components and connections. While, it's possible to drive the behavior of black-box from its components and its connections but understanding the behavior can be very difficult since it is obscured by the details of each component and connection.
Eventually, physical design describe different dimension of each component.

The Y-chart also defines multiple level of abstractions for a design by drawing concentric circles on the Y. Typically, four levels are used: system, processor, logic and circuit levels.
The name of each abstraction level is derived from the types of the components generated on that abstraction level.
For instance, on the processor level, we generate standard and custom processors, or special-hardware components such as memory controllers, arbiters, brides and various interface components. At the higher level, system level, we design standard or embedded systems consisting of processors, memories, buses, and other processor components.

Let's look at binary counter as an example. In this example at the algorithmic-level, we only know that at every cycle the input value will be increased by one and the output in the next cycle would be the input plus one.
At the next lower level, we understand that to carry out this function some sort of register is needed to hold the value of the counter.
We can state this idea using a register transfer statement such as $AC \leftarrow AC + 1$.
On the structural side, the register consists of gates and flip-flops, which themselves consist of transistors.

On each abstraction level, we need a library of components to be used in building \emph{the structure} for a given \emph{behavior}.
This process of converting the given behavior into a structure for a given haviour is called \textbf{synthesis}.
Once a structure is defined and verified, we can proceed to the next lower abstraction level by further synthesizing each of the components in the structure.
On the other hand, if each component in the library is given with its structure and
the physical implementation, we can proceed with physical design.
Thus each component in the library may have up to three different models representing
three different axes in the Y-Chart: behavior or function; structure, which
contains the components from the lower level of abstraction; and the physical.

In the rest of this chapter we focus on the first two level of abstractions, \textit{Processr} and \textit{System}.
Fortunately, all three models for each component are not typically needed most of the time.
Most of the methodologies presently in use perform design or synthesis on the system and processor levels, where every system component except standard processors and memories is synthesized to the logic level, before the physical design is performed on the logic level.
Therefore, for the top three abstraction levels, we only need a functional model of each component with estimates of the key metrics such as performance, delay, power, cost, size, reliability, testability, etc.
Once the design is represented in terms of logic gates and flip-flops, we can use standard cells for each logic component and perform layout placement and routing.
On the other hand, some components on the processor-and-system levels may be obtained as IPs and not synthesized.
Therefore, their structure and physical design are known, at least partially, on the level higher than logic level.
In that case, the physical design then may contain components of different sizes and from different levels of abstraction.

We first explain behavioral model and structural model of each level of abstraction. And then we explain the procedure or moving from behavioral domain to procedural domain.


\section{Processor-Level Behavioral Model}
\label{sec:processor_level_behavioral_model}

On the processor level, we define and design computational components or processing elements (PEs).
Each PE can be a dedicated or custom component that computes some specific functions, or it can be a general or standard PE that can compute any function specified in some standard programming language.
The functionality or behavior of each PE can be specified in several different ways.

In the basic implementation of PEs, their functionality can be specified with mathematical expressions or formulas.
But there is no limitation on what the functionaly of a PE can be.
Therefore, we can expand the functionality of a PE and specify it with an algorithm in some \textit{programming language}.
If we want to go beyond a mathematical expression, we solution is to use Finite State Machines (FSMs).
A FSM is defined with a set of states and a set of transitions from state to state, which are taken when some input variables reach the required value. Furthermore, each FSM generates some val- ues for output variables in each state or during each transition. A FSM model can be made clock-accurate if each state is considered to take one clock cycle. In general, a FSM model is useful for computations requiring several hundred states at most.

This FSM model use standard integer or floating-point variables and computing their values in each state or during each transition by a set of arithmetic expressions or programming statements.
For example, Figure~\ref{fig:fsm_model} shows a FSM with three states, S1, S2, and S3, and with arcs representing state changes under different inputs.
Each state executes a computation represented by one or more arithmetic expressions or programming statements.
For example, in state S1, the FSM in Figure~\ref{fig:fsm_model} computes two functions, $x = |a|$ and $y = |b|$, and in state S3 it computes the function $z = max (x, y)$.
A FSM model is usually not clock-accurate since computation in each state may take more than one clock cycle.
Therefore, using FSM model to represent computation expressed by programming languages like C is not adequet.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/Introduction/FSM.pdf}
    \caption{FSM model}
    \label{fig:fsm_model}
\end{figure}


In general, programming languages consist of \code{if} statements, loops, and expressions.
An \code{if} statement has two parts, then and else, in which then is executed \code{if} the conditional expression given in the \code{if} statement is true, otherwise the else part is executed.
In each of the then or else parts, the \code{if} statement computes \emph{a set of expressions called a Basic Block (BB)}.
The \code{if} statement can also be used in the loop construct to represent loop iterations, which are executed as long as the condition in the \code{if} statement is true.
Therefore, any programming-language code can be represented by a Control-Data Flow Graph (CDFG) consisting of \code{if} diamonds, which represent \code{if} conditions, and BB blocks, which represent computation [151].
Figure~\ref{fig:dcfg_model} shows such a CDFG, this one representing a loop with an \code{if} statement inside the loop iteration.
In each iteration, the loop construct executes BB1 and BB2 or BB3 depending on the value of \code{if} statement.
At the end, the loop is exited if all all iterations are executed.

A CDFG shows explicitly the control dependencies between loop statements, if statements, and BBs, as well as the data dependences among operations inside a BB.
It can be converted to a FSM by assigning a state to each BB and one state for the computation of each if conditional.
Note that each state in such a FSM may need several clock cycles to execute its assigned BB or if condition.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/Introduction/CFG.pdf}
    \caption{FSM model}
    \label{fig:dcfg_model}
\end{figure}

\section{Processor-Level Structural Model}

A processor’s behavioral model, whether defined by a program in C, CDFG, FSM, or by an IS, can be implemented with a set of register-transfer components; such a structural model usually consists of a controller and a datapath like general purpose processors.
A datapath consists of a set of storage elements (such as registers, register files, and memories), a set of functional units (such as ALUs, multipliers, shifters, and other custom functional units), and a set of busses.
All of these register-transfer components may be allocated in different quantities and types and connected arbitrarily through busses or a network-on-chip (NOC).
Each component may take one or more clock cycles to execute, each component may be pipelined, and each component may have input or output latches or registers.
In addition, the entire datapath can be pipelined in several stages in addition to components being pipelined by themselves.
The choice of components and datapath structure depends on the metrics to be optimized for particular implementation.

The controller defines the state of the processor clock cycle per clock cycle and issues the control signals for the datapath accordingly.
The structure of the controller and its implementation depends on whether the processor is a standard processor (such as Xeon, ARM, or a DSP) or a custom-design processor or Intellectual Property (IP) function specifically synthesized for a particular application and platform.
For instance, in the case of a standard processor, the controller is programmable with a program counter (PC), and an address generator (AG) that defines the next address to be loaded into the PC.
In the case of specific custom processors, the controller can be implemented with programmability concepts typical of standard processors, and control signal generation of IP implementations like CGRAs.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/Introduction/Processor_Structure.pdf}
    \caption{Processor structure model}
    \label{fig:proc_synthesis}
\end{figure}



\section{Processor-Level Synthesis}

Synthesis of standard processors starts with the instruction set (IS) of the processor.
In order to achieve the highest processor performance this process is done manually since standard processors try to achieve the highest performance and minimal power consumption at minimal cost.
The second reason for synthesizing processors manually is to minimize the design size and therefore fabrication cost for high-volume production.
In contrast, the design or synthesis of a custom processor or a custom IP starts with the C code of an algorithm, which is usually converted to the corresponding CDFG or FSMD model before synthesis and ends up with a custom processor containing the number and type of components connected as required by the given behavioral model.
This generation is usually called high-level synthesis or register-transfer synthesis or occasionally just processor synthesis.
Selecting components and the structure of a PE and \emph{defining register-transfer operations performed in each clock cycle is the task of processor-level synthesis.}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Introduction/processor-synthesis.pdf}
    \caption{High-Level Synthesis (HLS)}
    \label{fig:proc_synthesis}
\end{figure}


\section{System-Level Model}

Processor-level behavioral models such as the CDFG can be used for specifying a single processor, but will not suffice for describing a complete system that consist of many communicating processors.
A system-level model must represent multiple processes running in parallel in SW and HW.
The easiest way to do this is to use a model which retains the concept of states and transitions as in a FSM but which extends the computation in each state to include processes or procedures written in a programming language such as C/C++.
Furthermore, in order to represent a many-processor platform working in parallel or in pipelined mode, we must introduce concurrency and pipelining.
Since processes in a system run concurrently, we need a synchronization mechanism for data exchange, such as the concept of a channel, to encapsulate data communication.
Also, we need a model which supports hierarchy, so as to allow designers to write complex system specifications without difficulty.
Figure~\ref{fig:task_graph} illustrates such a model of hierarchical sequential-parallel processes, which is
usually called a Process State Machine (PSM).
This particular PSM is a system-level behavior or system specification, consisting of processes P1 to P5.
The
system starts with P1, which in turn triggers process P2 if condition d is true, or
another process consisting of P3, P4, and P5 if condition d is not true. P3 and
P4 run sequentially and in parallel with P5, as indicated by the vertical dashed
line. When either P2 is finished or the sequential-parallel composition of P3,
P4, and P5 is finished, the execution ends.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/Introduction/Task_Graph.pdf}
    \caption{System behavioral model}
    \label{fig:task_graph}
\end{figure}


In the synthesis part we need to answer question like what is the memory model. How is the memory shared across different processes.



\subsection{Missing Semantics}
\label{sec:missing_semantics}

A big challenge in \emph{synthesising} is missing semantics. In many cases there are many different representation and design for a same behavioral model. But which model fits better in our design. 
As an example of this problem, we can look in ~\ref{fig:missing_semantics} at a simple case statement available in any hardware or system modeling language.
This type of case statement can be used to model a FSM in which every case such as X1,X2, ..., represents a state in which all its next states are de ned.
This type of case statement can also be used to model a look-up table, in which every case X1, X2, ..., indicates a location in the memory that contains a value in the table.
Therefore,  we can use the same case statement with the same variables and format to describe two completely different components.
Unfortunately, FSMs and look-up tables require completely different implementations:  a FSM can be implemented with a controller or with logic gates, while a look-up table is usually implemented with some kind of memory.
It is also possible to implement a FSM with a memory or a table using logic gates.
However, this would not bea very ef cient implementation, and it would not be acceptable to any designer.
So a model which uses case statements to model FSMs and tables is good for simulation but not for implementation because neither a designer nor a synthesis tool can determine which type of structure was described by the case statement.
The lesson is that contemporary modeling languages allow modelers to de-scribe the design in many different ways and to use the same description for different designs details. But for automatic refinement, synthesis, and veri cation, we need clean and unambiguous semantic which uniquely represents all the system concepts in a given model.  Such a clean semantic is missing from most of the simulation-oriented  languages.
In order to have well defined semantics, we need to introduce some form of formalism to models and modeling languages.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Introduction/Missing_Semantics.pdf}
    \caption{Missing Semantics}
    \label{fig:missing_semantics}
\end{figure}




\section{Hardware Design Methodologies}

\paragraph{Method1:} Describe-and-Synthesize methodology (late 1980s to late 1990s). The 1980s brought us tools for logic synthesis which have significantly altered design flow, since the behavior and structure of a design were both captured on the logic level. Designers specified first what they wanted in Boolean equations or FSM descriptions, and then the synthesis tools generated the implementation in terms of a logic-level netlists. In this methodology therefore, the behavior or function comes first, and the structure or implementation comes afterwards. Moreover, both of these descriptions are simulatable, which is an marked improvement over Capture-and-Simulate methodology, because it permits much more efficient verification; it makes it possible to verify the descriptions’ equivalence since both descriptions can in principle be reduced to a canonical form. However, today’s designs are too large for this kind of equivalence checking.
By the late 1990s, the logic level had been abstracted to the Register-Transfer Level (RTL) with the introduction of cycle-accurate modeling and synthesis. Therefore, we now have two abstraction levels (RTL and logic levels) and two different models on each level (behavioral and structural). However, the system gap still persists because there was not relation between RTL and higher system level.

\paragraph{Mode2:} By the late 1990s, the logic level had been abstracted to the Register-Transfer Level (RTL) with the introduction of cycle-accurate modeling and synthesis. Therefore, we now have two abstraction levels (RTL and logic levels) and two different models on each level (behavioral and structural). However, the system gap still persists because there was not relation between RTL and higher system level.

Specify, Explore-and-Refine methodology (early 2000s to present). In order to close this gap, we must increase the level of abstraction from the RTL to the system level (SL) and to introduce a methodology that includes both SW and HW. On the SL, we can start with an executable specification that represents the system behavior; we can then extend the system-level methodology to include several models with different details that correspond to different design decisions. Each model is used to prove some system property: functionality, application algorithms, connectivity, communication, synchronization, coherence, routing, performance, or some design metric such as performance, power, and so on. So we must deal with several models in order to verify the impact of design decisions on every metric starting from an executable specification down to the RTL and further to the physical design. We can consider each model as a specification for the next level model, in which more implementation detail is added after more design decisions are made. We can label this a Specify-Explore-Refine (SER) methodology [63, 100], in that it consists of a sequence of models in which each model is a refinement of the previous. Thus SER methodology follows the natural design process in which de- signers specify the intent first, then explore possibilities, and finally refine the model according to their decisions. SER flow can therefore be viewed as several iterations of the basic Describe-and-Synthesize methodology.

% The first two clear advantages of automation of design process is first, it assures a much shorter design cycle, second, it allows for more exploration of different design style since different designs can be generated and evaluated quickly.
% And the ultimate goal of automation process is to out-perform average human designers in generating high quality designs. Another main advantages of synthesis is to capture the designer knowledge so that the process of making follow-on chip(s) is much easier and automated although human quality can be achieved on a single task.

% Currently, there are two schools of toughs to design a hardware. The first school is capture-and-simulation school believes that human designers have very good design knowledge accumulated through experience that \emph{cannot be automated}. In this case, programming FPGAs involves using a combination of vendor-supplied IP blocks, hand tuned hardware modules written using either low-level RTL or high-level synthesis tools, and architecture-specific glue logic to communicate with off-chip components such as DRAM.

% The second school believes to describe the design and high level and synthesis from description. This school believes that a top-down methodology, in which designers describe the intent of the design and automation tool's add detailed structure, would be better suited for the complex designs. This approach focuses on definition of description languages, design models and synthesis algorithms. In this model, designers' intuition can substantially reduce the search through the design space.


% We define design synthesis, broadly speaking, as a translation process from a behavioral description into a structural description.


% \paragraph{Describing Y-Chart here to clarify both thoughts}

% \section{Languages, Design and Technologies}
% Synthesis systems must allow for making design tradeoffs using different design styles for different technologies and design goals.

% Some design methodologies like pipelining can be abstracted into language constructs to provide better understanding and simpler synthesis algorithms.

% Unfortunately, each design can be described or modeled using a single language in several different ways.A

% Similarly, a design implementation is not unique.For each function in the design, there are several design styles suitable for different design goals or constraints.

% HLS still lacks a formalism of the type already developed for layout and logic synthesis. HLS uses formalisms based on several different areas, varying from the programming-language paradigm for the behavioral description to layout models for cost and performance estimation.


% The main problem with a design description is its change with the design over time. At the beginning, the description is vague, with little or no implementation detail. More detail is added as the design evolves, and the level of abstraction is lowered until the design is ready for manufacturing. A language that spans all the levels of abstraction would be desirable from a management point of view but would be too cumbersome to be mastered by designers, who work only on one or two levels of abstractions.

% Furthermore, different members of the design team require different aspects of a design, for reasons of verifiability, testability, reliability, information needed by those experts to one language known to everybody would produce a very rich language in which information for any particular aspect of the design would be difficult to find.



\subsection{Hardware definition languages}

Hardware description languages like Verilog and VHDL are designed for arbitrary circuit description.
Initially, these languages are developed as hardware simulation languages, and were only later adopted as a basis for hardware design.
While HDL language syntaxes' resemble software languages but they concepts are inherently different from software languages.
Software programs are inherently design to describe an algorithm for processors.
They have sequential semantics and correctness of the program is defined as executing instructions in the order it is written. Data movement is implicit between instructions and there is a explicit defined memory model.
In contrast, HLD languages are designed to specify circuit designs.
Hardware inherently is concurrent, therefor, each statement in HDL language is concurrent with other statements.
All the dependencies need to be explicit either in the form of wire or register.
There is no pre-defined memory model. Memory model needs to be explicitly defined and handled in the design.
Because the semantics of these languages are based around simulation, synthesizable designs must be inferred from a subset of the language, complicating tool development and designer education.
They can result in ambiguities that make automated synthesis and verification impossible, due to the unclear semantics involved.
For any design in order to achieve maximum generality, they require users to explicitly manage timing, control signals, and local memories.

A big limitation of HDL languages is that these languages lack the powerful abstraction facilities that
are common in modern software languages, which leads to low designer productivity by making it difficult to reuse components~\cite{shacham_rethinking_2010}.
Constructing efficient hardware designs requires extensive design-space exploration of alternative system microarchitectures but traditional HLDs have limited module generation facilities and are ill-suited to producing and composing the highly parameterized module generators required to support through design-space exploration.
Recent extensions such as SystemVerilog improve the type system and parameterized generate facilities but still lack many powerful programming language features.
But why reusing components is important?
The key benefit of reusing hardware components is that every time a chip is built, we inherently evaluate different design decisions, either implicitly using microarchitectural and domain knowledge, or explicitly through custom evaluation tools.
Rather than building a custom chip, designers create a template, or a chip generator, that can generate the specialized chip. Tensilica applied the same idea to create customized processors~\cite{tensillica}~\cite{tensillica}.

Genesis2~\cite{genesis2} was one of the first attempts to work around these limitations. Genesis2 uses Perl language as a macro processing language to provide more flexible parameterization and elaboration of underlying hardware blocks in SystemVerilog. Listing~\ref{listing:genesis2} shows an example of \textit{Genesis2's code}.

\begin{listing}[ht]
    \begin{minted}{Verilog}
        //; # More Perl Libraries
        //; use POSIX (ceil);
        //; my $reg_list = $self->define_param(REG_LIST => 
        //; [	
        //;     {name => 'regA', width => 5, default => 17, IEO => 'ie'},
        //;     {name => 'regB', width => 10, default => 27, IEO => 'o'},
        //;     {name => 'regC', width => 15, IEO => 'ieo'},
        //;     {name => 'regD', width => 31, IEO => 'ieo'},
        //;     {name => 'regE', width => 32, IEO => 'ieo'},
        //; ]);
        //; my $num_regs = scalar(@{$reg_list});
        //; my $num_addr_bits = ceil(log($num_regs)/log(2));

        // Verilog code for the module
        module 'mname()' (
            input                               Clk,
            input                               Reset,
            input ['$num_addr_bits-1':0]        Addr,
            ...
            );

        endmodule // 'mname()'
    \end{minted}
    \caption[Caption for LOF]%
    {Genesis2 code example, combining SystemVerilog and Perl~\cite{genesis2}}
    \label{listing:genesis2}
\end{listing}

In this example, perl is using ceil libarary from POSIX library to set the values for $\$num\_add\_bits$.

These approaches allow familiar and powerful languages like Verilog to be macro languages for hardware netlists, but effectively require leaf components of the design to be described in the underlying HDL.
This combined approach is cumbersome, combining the poor abstraction facilities of the underlying HDL with a completely different high-level programming model that does not understand hardware types and semantics.

Another alternative proposal to improve productivity of HLD languages was beginning from a domain-specific application programming language and then generate hardware blocks. 
Bluespec~\cite{bluespec} is an example of such languages.
Bluespec Compiler (BSC) is a tool that uses BluespecSystem  Verilog  (BSV)  as  the  design  language.
BSV is a high-level functional HDL based on Verilog and inspired by Haskell, where  modules are implemented as a set of rules using  Verilog  syntax.
The rules are called guarded atomic actions and express behavior in the form of concurrently cooperating finite state machines (FSMs).
Rules are predicated witha condition. They give the impression of freezing the rest of the system when a given rule's action is carried out after the rule's predicate is true.
There is an implicit parallelism in this specification, because it is possible for multiple rules to be activated and executed in parallel.
The compiler automatically schedules the rules such that they are either conflict-free or combined sequentially to preserve the promised atomicity semantic.


% One exception to this is Bluespec SystemVerilog \cite{bluespec}, which supports state machine inference from nested while loops.
% Recent advancements in HDLs have largely been aimed at meta-programming improvements and increasing the size of hardware module libraries.
% Languages like Chisel~\cite{chisel}, MyHDL~\cite{decaluwe_2004_myhdl} and VeriScala~\cite{veriscala} make procedural generation of circuits simpler by embedding their HDL in a software language (e.g. Scala or Python). Similarly, Genesis2~\cite{genesis2} adds Perl scripting support to SystemVerilog to help drive procedural generation. While these improvements allow for more powerful meta-programming compared to Verilog \texttt{\small{generate}} statements, users still write programs at a timed circuit level.
%For application accelerators, such a low level of abstraction is often too tedious.


\subsection{Chisel}
Chisel~\cite{chisel}
% * Adding support for meta-programming 
% * Improve modular hardware library design
%





While their syntax is at least reminiscent of high-level software languages, the specification of a circuit in an HDL is different from writing a software program. Software programs have a sequential execution model in which correctness is defined as the execution of each instruction or function in the order it is written.
The movement of data is implicit and is left to the underling hardware.

Memory accesses are inferred, and processors provide implicit support for interfaces to memory. By contrast, hardware designs consist of blocks of circuitry that all run concurrently. Data movement is written explicitly into the model, in the form of wires and ports. Memory and memory accesses must be explicitly declared and handled [Martinez et al., 2008]. Listing 2.1 shows the VHDL implementation of a 1-bit half adder along with its RTL implementation in Figure 2.10. A half adder adds two input bits A and B and generates two outputs a carry and sum. Table 2.1 shows the truth table of a half adder.










The dominant traditional hardware-description languages
(HDLs), Verilog and VHDL, were originally developed as
hardware simulation languages, and were only later adopted
as a basis for hardware synthesis. Because the semantics of
these languages are based around simulation, synthesizable
designs must be inferred from a subset of the language, complicating tool development and designer education. These
languages also lack the powerful abstraction facilities that
are common in modern software languages, which leads to
low designer productivity by making it difficult to reuse components. Constructing efficient hardware designs requires
extensive design-space exploration of alternative system microarchitectures [9] but these traditional HDLs have limited
module generation facilities and are ill-suited to producing
and composing the highly parameterized module generators
required to support thorough design-space exploration. Recent extensions such as SystemVerilog improve the type system and parameterized generate facilities but still lack many
powerful programming language features.
To work around these limitations, one common approach
is to use another language as a macro processing language
for an underlying HDL. For example, Genesis2 uses Perl to
provide more flexible parameterization and elaboration of
hardware blocks written in SystemVerilog [9]. The language
called Verischemelog [6] provides a Scheme syntax for specifying modules in a similar format to Verilog. JHDL [1]
equates Java classes with modules. HML [7] uses standard
ML functions to wire together a circuit. These approaches
allow familiar and powerful languages to be macro languages
for hardware netlists, but effectively require leaf components
of the design to be described in the underlying HDL. This
combined approach is cumbersome, combining the poor abstraction facilities of the underlying HDL with a completely
different high-level programming model that does not understand hardware types and semantics.
An alternative approach is to begin from a domain-specific
application programming language from which a hardware
block is generated. Esterel [2] uses event-based statements
to program hardware for reactive systems. DIL [4] is an intermediate language targeted at stream processing and hardware virtualization. Bluespec [3] supports a general concurrent computation model, based on guarded atomic actions.
generator to explore this design space in detail.


In this paper, we introduce Chisel (Constructing Hardware In a Scala Embedded Language), a new hardware design language we have developed based on the Scala programming language [8]. Chisel is intended to be a simple
platform that provides modern programming language features for accurately specifying low-level hardware blocks,
but which can be readily extended to capture many useful high-level hardware design patterns. By using a flexible
platform, each module in a project can employ whichever
design pattern best fits that design, and designers can freely
combine multiple modules regardless of their programming
model. Chisel can generate fast cycle-accurate C++ simulators for a design, or generate low-level Verilog suitable for
either FPGA emulation or ASIC synthesis with standard
tools. We present several design examples and results from
emulation and synthesis experiments.
While these can provide great designer productivity when
the task in hand matches the pattern encoded in the application programming model, they are a poor match for tasks
outside their domain. For example, the design of a programmable microprocessor is not well described in a stream
programming model, and guarded atomic actions are not a
natural way to express a high-level DSP algorithm. Furthermore, in general it is difficult to derive an efficient microarchitecture from a higher-level computation model, especially
if the goal is a programmable engine to run many applications, where the human designer would prefer to write a

\subsection{Firrtl}
Firrtl~\cite{izraelevitz_2017_firrtl_reusability, firrtl}
% * Compiler


\section{Spatial}
Spatial~\cite{david_PLDI_2018_spatial, prabhakar_asplos_2016_parallelpattern}




