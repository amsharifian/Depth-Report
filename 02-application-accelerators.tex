%!TEX root = main.tex

% NOTES:
%   * There is a shift to accelerator design
%   * CPUs are inefficient
%   * Fixed accelerators are hard to program
%   * Alternative is FPGA/CGRA
%   * There are challenges with programming FPGA/CGRA
%   * HLS is one solution
%

\section{Why application specific accelerators?}
\label{background:accel}


Recent trends in technology scaling, the availability of large amounts of data, and novel algorithmic breakthroughs have spurred accelerator architecture research.
In a general-purpose microprocessor, the overhead of instruction processing is much higher than the actual operations performed by each instruction.
This overhead includes the necessary steps to fetch and decode the instructions, provide required operands for the instructions, and perform the necessary bookkeeping to ensure correctness when multiple instructions are executing in the microprocessor.
Conversely, application specific hardware are faster and lower in power consumption than general-purpose processors because they eliminate most of the overhead of a general purpose processor~\cite{chung_micro_2010, hameed_asplos_2010_understanding}.
Although fixed-function accelerators are more energy efficient than software running a general-purpose processor, they are not a suitable solution for applications that change frequently.
As an alternative to fixed-function accelerators, reconfigurable architectures like field-programmable gate arrays (FPGAs) and coarse-grain reconfigurable architectures (CGRAs) have received renewed interest from academic researchers and industry practitioners alike, primarily due to their potential performance and energy efficiency benefits over conventional CPUs.
For instance, FPGAs are now being used to accelerate web search in datacenters at Microsoft and Baidu~\cite{catapult, baidu}, Amazon now offers FPGA instances as part of AWS~\cite{awsf1}, and Intel has announced products like in-package Xeon-FPGA systems~\cite{harp} and FPGA-accelerated storage systems~\cite{nand_flash}. Similarly, several recent research prototypes~\cite{dyser, triggered_instruction, scaledeep, scnn, plasticine, cgra_me} have explored various kinds of CGRAs at different granularity. Growing use of such reconfigurable architectures has made them more available to programmers now than ever before.
Although the flexibility of reconfigurable architectures enables changing the application by reconfiguring the accelerator, their programmability is still a major obstacle for their wide spread use.

\section{The need for Design Automation on Higher Abstraction Levels}

Reconfigurable devices, usually, accelerates part of the application which contains regular control flow and abundant data parallelism to achieve high performance and efficiency~\cite{spatial_computation, trips, govindaraju_hpca_2011}.
They can exploit: 1)multiple levels of nested parallelism, 2)data locality with custom data pipelines and 3)defining custom memory hierarchies.
Unfortunately, \textit{all the features that make reconfigurable architectures efficient also make them much more complex to program.}
For instance, in FPGAs, an accelerator design must account for the timing between pipelined signals and the physically limited compute and memory resources available on the target device.
It must also manage partitioning of data between local scratchpads and off-chip memory to achieve good data locality~\cite{gzip_2013_fpga}.
The combination of these complexities leads to intractable accelerator design spaces, even for relatively small applications~\cite{cascaval_taxonomy_accelerator}.

These challenges have caused \emph{programmability} to be a key limiting factor to widespread adoption of reconfigurable architectures~\cite{fpga_masses, cgra_architecture}.

\textbf{Design productivity gap}
% The Semiconductor Industry Association (SIA)2 shows that a design productivity gap exists between the available chip capacity and the current design capabilities. Figure 2.3 plots Moore’s Law, together with the productivity growth, expressed in transistors per staff member per month over the last decades. Due to improving engineering skills, an increase in the number of transistors that one designer can handle can be observed. The pace at which the design productivity increases is, however, much smaller than the slope of Moore’s Low. That is, whereas Moore’s Low predicts that the chip capacity doubles every eighteen months, the hardware design productivity in the past few years is estimated to increase at 1.6× over the same period of time. As can be seen from Figure 2.3, the design productivity gap originate from the 1980s. At that moment, it became clear that it was no longer possible in digital design to cope with every transistor individually. This ”design crisis” was the driven force behind the introduction of design abstraction levels [Bell and Newell, 1971] together with well-defined design methodologies and the advent of the automation of the design of electronic systems and circuits (Electronic Design Automation (EDA)) [Lavagno et al., 2006]. Hence, design methodologies become a popular research topic to tackle these aforementioned design challenges of embedded systems in the recent decade.


% Currently, there are two schools of toughs to program FPGAs. The first technique is capture-and-simulation school believes that human designers have very good design knowledge accumulated through experience that \emph{cannot be automated}. In this case, programming FPGAs involves using a combination of vendor-supplied IP blocks, hand tuned hardware modules written using either low-level RTL or high-level synthesis tools, and architecture-specific glue logic to communicate with off-chip components such as DRAM.

% The second school believes to describe the design and high level and synthesis from description. This school believes that a top-down methodology, in which designers describe the intent of the design and automation tool's add detailed structure, would be better suited for the complex designs. This approach focuses on definition of description languages, design models and synthesis algorithms. In this model, designers' intuition can substantially reduce the search through the design space.

% \paragraph{Describing Y-Chart here to clarify both thoughts}

\section{Levels of abstraction}

In summary, we define design synthesis, broadly speaking, as a translation process from a behavioral description into a structural description.

\section{Languages, Design and Technologies}
Synthesis systems must allow for making design tradeoffs using different design styles for different technologies and design goals.

Some design methodologies like pipelining can be abstracted into language constructs to provide better understanding and simpler synthesis algorithms.

Unfortunately, each design can be described or modeled using a single language in several different ways.A

Similarly, a design implementation is not unique.For each function in the design, there are several design styles suitable for different design goals or constraints.

HLS still lacks a formalism of the type already developed for layout and logic synthesis. HLS uses formalisms based on several different areas, varying from the programming-language paradigm for the behavioral description to layout models for cost and performance estimation.


The main problem with a design description is its change with the design over time. At the beginning, the description is vague, with little or no implementation detail. More detail is added as the design evolves, and the level of abstraction is lowered until the design is ready for manufacturing. A language that spans all the levels of abstraction would be desirable from a management point of view but would be too cumbersome to be mastered by designers, who work only on one or two levels of abstractions.

Furthermore, different members of the design team require different aspects of a design, for reasons of verifiability, testability, reliability, information needed by those experts to one language known to everybody would produce a very rich language in which information for any particular aspect of the design would be difficult to find.

\section{Hardware design methodology}

In order to explain the different design methodologies, we use the Y-Chart, which was introduced in 1983 by Gajski and Kuhn~\cite{gajski_1992_high} and refined by Walker and Thomas~\cite{walker_1985_y_model}.
The Gajski-Kuhn Y-chart is depicted in Figure 2.4(a). This model of design representation is described using three axes, each representing one of three domains of description-behavioral, structural, and physical. The

\begin{enumerate}
    \item \textbf{Behavioral: } Describes the behavior or the functionality of an algorithm.
    \item \textbf{Structural: } Describes the abstract implementation, or logical structure, of the design as a hierarchy of components and their interconnection.
    \item \textbf{Physical: }  Describes the physical implementation of the design.
\end{enumerate}
