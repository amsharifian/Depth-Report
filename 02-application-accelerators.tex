%!TEX root = main.tex

% NOTES:
%   * There is a shift to accelerator design
%   * CPUs are inefficient
%   * Fixed accelerators are hard to program
%   * Alternative is FPGA/CGRA
%   * There are challenges with programming FPGA/CGRA
%   * HLS is one solution
%

\section{Why application specific accelerators?}
\label{background:accel}


Recent trends in technology scaling, the availability of large amounts of data, and novel algorithmic breakthroughs have spurred accelerator architecture research.
In a general-purpose microprocessor, the overhead of instruction processing is much higher than the actual operations performed by each instruction.
This overhead includes the necessary steps to fetch and decode the instructions, provide required operands for the instructions, and perform the necessary bookkeeping to ensure correctness when multiple instructions are executing in the microprocessor.
Conversely, application specific hardware are faster and lower in power consumption than general-purpose processors because they eliminate most of the overhead of a general purpose processor~\cite{chung_micro_2010, hameed_asplos_2010_understanding}.
Although fixed-function accelerators are more energy efficient than software running a general-purpose processor, they are not a suitable solution for applications that change frequently.
As an alternative to fixed-function accelerators, reconfigurable architectures like field-programmable gate arrays (FPGAs) and coarse-grain reconfigurable architectures (CGRAs) have received renewed interest from academic researchers and industry practitioners alike, primarily due to their potential performance and energy efficiency benefits over conventional CPUs.
For instance, FPGAs are now being used to accelerate web search in datacenters at Microsoft and Baidu~\cite{catapult, baidu}, Amazon now offers FPGA instances as part of AWS~\cite{awsf1}, and Intel has announced products like in-package Xeon-FPGA systems~\cite{harp} and FPGA-accelerated storage systems~\cite{nand_flash}. Similarly, several recent research prototypes~\cite{dyser, triggered_instruction, scaledeep, scnn, plasticine, cgra_me} have explored various kinds of CGRAs at different granularity. Growing use of such reconfigurable architectures has made them more available to programmers now than ever before.
Although the flexibility of reconfigurable architectures enables changing the application by reconfiguring the accelerator, their programmability is still a major obstacle for their wide spread use.

\textbf{Challenges:}
Reconfigurable devices, usually, accelerates part of the application which contains regular control flow and abundant data parallelism to achieve high performance and efficiency~\cite{spatial_computation, trips, govindaraju_hpca_2011}.
They can exploit: 1)multiple levels of nested parallelism, 2)data locality with custom data pipelines and 3)defining custom memory hierarchies.
Unfortunately, all the features that make reconfigurable architectures efficient also make them much more complex to program.
For instance, in FPGAs, an accelerator design must account for the timing between pipelined signals and the physically limited compute and memory resources available on the target device.
It must also manage partitioning of data between local scratchpads and off-chip memory to achieve good data locality~\cite{gzip_2013_fpga}.
The combination of these complexities leads to intractable accelerator design spaces, even for relatively small applications~\cite{cascaval_taxonomy_accelerator}.

These challenges have caused programmability to be a key limiting factor to widespread adoption of reconfigurable architectures~\cite{fpga_masses, cgra_architecture}.
Currently, the state of the art in programming FPGAs involves using a combination of vendor-supplied IP blocks, hand tuned hardware modules written using either low-level RTL or high-level synthesis tools, and architecture-specific glue logic to communicate with off-chip components such as DRAM.

Considering the above challenges, hardware designers use hardware description languages (HDLs) such as Verilog and VHDL to implement algorithm in hardware.
But these languages are designed for explicit specification of hardware, and they are aboard to express higher level information that exists at the algorithm level.

To overcome these challenges, there different approaches proposed which we look at them at the related works section.


\section{Levels of abstraction}

In summary, we define design synthesis, broadly speaking, as a translation process from a behavioral description into a structural description.

\section{Languages, Design and Technologies}
Synthesis systems must allow for making design tradeoffs using different design styles for different technologies and design goals.

Some design methodologies like pipelining can be abstracted into language constructs to provide better understanding and simpler synthesis algorithms.

Unfortunately, each design can be described or modeled using a single language in several different ways.A

Similarly, a design implementation is not unique.For each function in the design, there are several design styles suitable for different design goals or constraints.

HLS still lacks a formalism of the type already developed for layout and logic synthesis. HLS uses formalisms based on several different areas, varying from the programming-language paradigm for the behavioral description to layout models for cost and performance estimation.


The main problem with a design description is its change with the design over time. At the beginning, the description is vague, with little or no implementation detail. More detail is added as the design evolves, and the level of abstraction is lowered until the design is ready for manufacturing. A language that spans all the levels of abstraction would be desirable from a management point of view but would be too cumbersome to be mastered by designers, who work only on one or two levels of abstractions.

Furthermore, different members of the design team require different aspects of a design, for reasons of verifiability, testability, reliability, information needed by those experts to one language known to everybody would produce a very rich language in which information for any particular aspect of the design would be difficult to find.

\section{Hardware design methodology}

In order to explain the different design methodologies, we use the Y-Chart, which was introduced in 1983 by Gajski and Kuhn~\cite{gajski_1992_high} and refined by Walker and Thomas~\cite{walker_1985_y_model}.
The Gajski-Kuhn Y-chart is depicted in Figure 2.4(a). This model of design representation is described using three axes, each representing one of three domains of description-behavioral, structural, and physical. The

\begin{enumerate}
    \item \textbf{Behavioral: } Describes the behavior or the functionality of an algorithm.
    \item \textbf{Structural: } Describes the abstract implementation, or logical structure, of the design as a hierarchy of components and their interconnection.
    \item \textbf{Physical: }  Describes the physical implementation of the design.
\end{enumerate}
